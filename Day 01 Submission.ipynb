{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values = [\"n/a\", \"na\", \"--\", \" \"]\ntrain = pd.read_csv('/kaggle/input/data-storm-20/Hotel-A-train.csv', na_values = missing_values)\nvalidation = pd.read_csv('/kaggle/input/data-storm-20/Hotel-A-validation.csv', na_values = missing_values)\ntest = pd.read_csv('/kaggle/input/data-storm-20/Hotel-A-test.csv', na_values = missing_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(validation.isnull(), yticklabels=False, cbar=False, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(test.isnull(), yticklabels=False, cbar=False, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_copy = train.copy()\nvalidation_copy = validation.copy()\ntest_copy = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert object data to dates\n\nimport datetime\ntrain['Expected_checkin'] = pd.to_datetime(train['Expected_checkin'],dayfirst=False, yearfirst=False, format='%m/%d/%Y')\ntrain['Expected_checkout'] = pd.to_datetime(train['Expected_checkout'],dayfirst=True, yearfirst=True, format='%m/%d/%Y')\ntrain['Booking_date'] = pd.to_datetime(train['Booking_date'],dayfirst=True, yearfirst=True, format='%m/%d/%Y')\n\nvalidation['Expected_checkin'] = pd.to_datetime(validation['Expected_checkin'],dayfirst=False, yearfirst=False, format='%m/%d/%Y')\nvalidation['Expected_checkout'] = pd.to_datetime(validation['Expected_checkout'],dayfirst=True, yearfirst=True, format='%m/%d/%Y')\nvalidation['Booking_date'] = pd.to_datetime(validation['Booking_date'],dayfirst=True, yearfirst=True, format='%m/%d/%Y')\n\ntest['Expected_checkin'] = pd.to_datetime(test['Expected_checkin'],dayfirst=False, yearfirst=False, format='%m/%d/%Y')\ntest['Expected_checkout'] = pd.to_datetime(test['Expected_checkout'],dayfirst=True, yearfirst=True, format='%m/%d/%Y')\ntest['Booking_date'] = pd.to_datetime(test['Booking_date'],dayfirst=True, yearfirst=True, format='%m/%d/%Y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate number of days to stay and add a new column\nnumOfDays_train = []\nnumOfDays_valid = []\nnumOfDays_test = []\n\ndaysBeforeStay_train = []\ndaysBeforeStay_valid = []\ndaysBeforeStay_test = []\n\nRaws_train=train.shape[0]\nRaws_valid=validation.shape[0]\nRaws_test=test.shape[0]\n\nfor i in range(Raws_train):\n    k=str(abs(train.Expected_checkin[i]-train.Expected_checkout[i])) #get the difference and convert to string\n    x=str(abs(train.Expected_checkin[i]-train.Booking_date[i])) #days befor stay\n    Days=int(k[:1]) #num.ofDays\n    daysBeforeStay=int(x[:1]) #num.ofDaysBeforeStay\n    numOfDays_train.append(Days)\n    daysBeforeStay_train.append(daysBeforeStay)\n\nfor i in range(Raws_valid):\n    k=str(abs(validation.Expected_checkin[i]-validation.Expected_checkout[i])) #get the difference and convert to string\n    x=str(abs(validation.Expected_checkin[i]-validation.Booking_date[i])) #days befor stay\n    Days=int(k[:1]) #num.ofDays\n    daysBeforeStay=int(x[:1]) #num.ofDaysBeforeStay\n    numOfDays_valid.append(Days)\n    daysBeforeStay_valid.append(daysBeforeStay)\n\nfor i in range(Raws_test):\n    k=str(abs(test.Expected_checkin[i]-test.Expected_checkout[i])) #get the difference and convert to string\n    x=str(abs(test.Expected_checkin[i]-test.Booking_date[i])) #days befor stay\n    Days=int(k[:1]) #num.ofDays\n    daysBeforeStay=int(x[:1]) #num.ofDaysBeforeStay\n    numOfDays_test.append(Days)\n    daysBeforeStay_test.append(daysBeforeStay)\n    \ntrain.insert(10, 'days_stay', numOfDays_train, allow_duplicates = False)\nvalidation.insert(10, 'days_stay', numOfDays_valid, allow_duplicates = False)\ntest.insert(10, 'days_stay', numOfDays_test, allow_duplicates = False)\n\ntrain.insert(12, 'days_before_stay', daysBeforeStay_train, allow_duplicates = False)\nvalidation.insert(12, 'days_before_stay', daysBeforeStay_valid, allow_duplicates = False)\ntest.insert(12, 'days_before_stay', daysBeforeStay_test, allow_duplicates = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#min max normalization on 'Age','Room_Rate'\n\ntrain['Age'] = (train['Age']-train['Age'].min())/(train['Age'].max()-train['Age'].min())\ntrain['Room_Rate'] = (train['Room_Rate']-train['Room_Rate'].min())/(train['Room_Rate'].max()-train['Room_Rate'].min())\n\nvalidation['Age'] = (validation['Age']-validation['Age'].min())/(validation['Age'].max()-validation['Age'].min())\nvalidation['Room_Rate'] = (validation['Room_Rate']-validation['Room_Rate'].min())/(validation['Room_Rate'].max()-validation['Room_Rate'].min())\n\ntest['Age'] = (test['Age']-test['Age'].min())/(test['Age'].max()-test['Age'].min())\ntest['Room_Rate'] = (test['Room_Rate']-test['Room_Rate'].min())/(test['Room_Rate'].max()-test['Room_Rate'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TrainSet = train.drop(['Reservation-id','Expected_checkin','Expected_checkout','Booking_date'], axis = 1)\nValidationSet = validation.drop(['Reservation-id','Expected_checkin','Expected_checkout','Booking_date'], axis = 1)\nTestSet = test.drop(['Reservation-id','Expected_checkin','Expected_checkout','Booking_date'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One Hot Encoding\n\ncolumns = ['Gender','Ethnicity','Educational_Level','Income','Country_region','Hotel_Type','Meal_Type','Visted_Previously',\n           'Previous_Cancellations','Deposit_type','Booking_channel','Required_Car_Parking','Use_Promotion']\n\nfor col in columns:\n    one_hot = pd.get_dummies(TrainSet[col], prefix=col)\n    TrainSet = TrainSet.join(one_hot)\n\nfor col in columns:\n    one_hot = pd.get_dummies(ValidationSet[col], prefix=col)\n    ValidationSet = ValidationSet.join(one_hot)    \n\nfor col in columns:\n    one_hot = pd.get_dummies(TestSet[col], prefix=col)\n    TestSet = TestSet.join(one_hot) \n    \nTrainSet=TrainSet.drop(columns,axis=1)\nValidationSet=ValidationSet.drop(columns,axis=1)\nTestSet=TestSet.drop(columns,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Encoding\n\n#le = LabelEncoder()\n\n#TrainSet['Reservation_Status'] = le.fit_transform(TrainSet['Reservation_Status'])\n#ValidationSet['Reservation_Status'] = le.fit_transform(ValidationSet['Reservation_Status'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# By using Mapping Structure\n\nstatusMapping = {'Check-In': '1', 'Canceled':'2','No-Show':'3'}\nTrainSet['Reservation_Status']=TrainSet['Reservation_Status'].map(statusMapping)\nValidationSet['Reservation_Status']=ValidationSet['Reservation_Status'].map(statusMapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TrainSet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ValidationSet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TestSet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = TrainSet['Reservation_Status']\nX_train = TrainSet.drop('Reservation_Status', axis=1)\n\nY_test = ValidationSet['Reservation_Status']\nX_test = ValidationSet.drop('Reservation_Status', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **KNN Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#kNN classifier\n#Number of neighbors = 5\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nKNNclassifier = KNeighborsClassifier(n_neighbors=5)\nKNNclassifier.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = KNNclassifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix and classification report\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nconfusionMatrix = confusion_matrix(Y_test, Y_pred)\nprint('\\nConfusion Matrix: \\n',confusionMatrix)\nprint('\\nClassification Report: \\n',classification_report(Y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IDs = test['Reservation-id'].values.tolist()\nTestSet_pred = list(KNNclassifier.predict(TestSet))\n\ndata = {'Reservation-id': IDs,'Reservation_Status':TestSet_pred}\n\nDF = pd.DataFrame(data)\nDF.to_csv('Submission.csv', index=False) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}